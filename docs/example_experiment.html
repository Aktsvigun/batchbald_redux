---

title: Example Experiment

keywords: fastai
sidebar: home_sidebar

summary: "Experiment using Repeated MNIST and BatchBALD vs BALD vs random sampling"
description: "Experiment using Repeated MNIST and BatchBALD vs BALD vs random sampling"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: example_experiment.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This notebook ties everything together and runs an AL loop.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">blackhc.project.script</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="kn">from</span> <span class="nn">batchbald_redux</span> <span class="kn">import</span> <span class="n">active_learning</span><span class="p">,</span> <span class="n">batchbald</span><span class="p">,</span> <span class="n">consistent_mc_dropout</span><span class="p">,</span> <span class="n">joint_entropy</span><span class="p">,</span> <span class="n">repeated_mnist</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's define our Bayesian CNN model that we will use to train MNIST.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">BayesianCNN</span><span class="p">(</span><span class="n">consistent_mc_dropout</span><span class="o">.</span><span class="n">BayesianModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1_drop</span> <span class="o">=</span> <span class="n">consistent_mc_dropout</span><span class="o">.</span><span class="n">ConsistentMCDropout2d</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2_drop</span> <span class="o">=</span> <span class="n">consistent_mc_dropout</span><span class="o">.</span><span class="n">ConsistentMCDropout2d</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1_drop</span> <span class="o">=</span> <span class="n">consistent_mc_dropout</span><span class="o">.</span><span class="n">ConsistentMCDropout</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">mc_forward_impl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1_drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="nb">input</span><span class="p">)),</span> <span class="mi">2</span><span class="p">))</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2_drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="nb">input</span><span class="p">)),</span> <span class="mi">2</span><span class="p">))</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1_drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="nb">input</span><span class="p">)))</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">input</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Grab our dataset, we'll use Repeated-MNIST.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">repeated_mnist</span><span class="o">.</span><span class="n">create_repeated_MNIST_dataset</span><span class="p">(</span><span class="n">num_repetitions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">add_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_initial_samples</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">initial_samples</span> <span class="o">=</span> <span class="n">active_learning</span><span class="o">.</span><span class="n">get_balanced_sample_indices</span><span class="p">(</span>
    <span class="n">repeated_mnist</span><span class="o">.</span><span class="n">get_targets</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">),</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
    <span class="n">n_per_digit</span><span class="o">=</span><span class="n">num_initial_samples</span><span class="o">/</span><span class="n">num_classes</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># experiment</span>
<span class="n">max_training_samples</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">acquisition_batch_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">num_inference_samples</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">num_test_inference_samples</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">100000</span>

<span class="n">test_batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">scoring_batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">epoch_samples</span> <span class="o">=</span> <span class="mi">4096</span> <span class="o">*</span> <span class="mi">6</span>

<span class="n">use_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;use_cuda: </span><span class="si">{use_cuda}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;num_workers&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="p">{}</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span>
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">test_batch_size</span><span class="p">,</span>
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                          <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">active_learning_data</span> <span class="o">=</span> <span class="n">active_learning</span><span class="o">.</span><span class="n">ActiveLearningData</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>

<span class="c1"># Split off the initial samples first.</span>
<span class="n">active_learning_data</span><span class="o">.</span><span class="n">acquire</span><span class="p">(</span><span class="n">initial_samples</span><span class="p">)</span>

<span class="c1"># THIS REMOVES MOST OF THE POOL DATA. UNCOMMENT THIS TO TAKE ALL UNLABELLED DATA INTO ACCOUNT!</span>
<span class="n">active_learning_data</span><span class="o">.</span><span class="n">extract_dataset_from_pool</span><span class="p">(</span><span class="mi">40000</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">active_learning_data</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">,</span>
    <span class="n">sampler</span><span class="o">=</span><span class="n">active_learning</span><span class="o">.</span><span class="n">RandomFixedLengthSampler</span><span class="p">(</span>
        <span class="n">active_learning_data</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">,</span> <span class="n">epoch_samples</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">pool_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">,</span>
                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">scoring_batch_size</span><span class="p">,</span>
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                          <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="c1"># Run experiment</span>
<span class="n">test_accs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_loss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">added_indices</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">initial</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">),</span>
            <span class="n">total</span><span class="o">=</span><span class="n">max_training_samples</span><span class="p">,</span>
            <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training Set Size&quot;</span><span class="p">)</span>

<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">BayesianCNN</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># Train</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Test</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Testing&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

            <span class="n">prediction</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">(</span>
                <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">num_test_inference_samples</span><span class="p">),</span>
                <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">num_test_inference_samples</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">)</span>

            <span class="n">prediction</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">prediction</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">test_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

    <span class="n">percentage_correct</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">test_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">percentage_correct</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set: Average loss: </span><span class="si">{:.4f}</span><span class="s2">, Accuracy: </span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2"> (</span><span class="si">{:.2f}</span><span class="s2">%)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span> <span class="n">percentage_correct</span><span class="p">))</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">training_dataset</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">max_training_samples</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="c1"># Acquire pool predictions</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">)</span>
    <span class="n">logits_N_K_C</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">num_inference_samples</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">),</span>
                               <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">,</span>
                               <span class="n">pin_memory</span><span class="o">=</span><span class="n">use_cuda</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">tqdm</span><span class="p">(</span><span class="n">pool_loader</span><span class="p">,</span>
                     <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Evaluating Acquisition Set&quot;</span><span class="p">,</span>
                     <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

            <span class="n">lower</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">pool_loader</span><span class="o">.</span><span class="n">batch_size</span>
            <span class="n">upper</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">lower</span> <span class="o">+</span> <span class="n">pool_loader</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
            <span class="n">logits_N_K_C</span><span class="p">[</span><span class="n">lower</span><span class="p">:</span><span class="n">upper</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">model</span><span class="p">(</span>
                <span class="n">data</span><span class="p">,</span> <span class="n">num_inference_samples</span><span class="p">)</span><span class="o">.</span><span class="n">double</span><span class="p">(),</span>
                                            <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">candidate_batch</span> <span class="o">=</span> <span class="n">batchbald</span><span class="o">.</span><span class="n">get_batchbald_batch</span><span class="p">(</span><span class="n">logits_N_K_C</span><span class="p">,</span>
                                                        <span class="n">acquisition_batch_size</span><span class="p">,</span>
                                                        <span class="n">num_samples</span><span class="p">,</span>
                                                        <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">,</span>
                                                        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="n">targets</span> <span class="o">=</span> <span class="n">repeated_mnist</span><span class="o">.</span><span class="n">get_targets</span><span class="p">(</span><span class="n">active_learning_data</span><span class="o">.</span><span class="n">pool_dataset</span><span class="p">)</span>
    <span class="n">dataset_indices</span> <span class="o">=</span> <span class="n">active_learning_data</span><span class="o">.</span><span class="n">get_dataset_indices</span><span class="p">(</span>
        <span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dataset indices: &quot;</span><span class="p">,</span> <span class="n">dataset_indices</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Scores: &quot;</span><span class="p">,</span> <span class="n">candidate_batch</span><span class="o">.</span><span class="n">scores</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Labels: &quot;</span><span class="p">,</span> <span class="n">targets</span><span class="p">[</span><span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span><span class="p">])</span>

    <span class="n">active_learning_data</span><span class="o">.</span><span class="n">acquire</span><span class="p">(</span><span class="n">candidate_batch</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span>
    <span class="n">added_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataset_indices</span><span class="p">)</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset_indices</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>use_cuda: True
Test set: Average loss: 1.8308, Accuracy: 6338/10000 (63.38%)
Dataset indices:  [ 8289  3582 53863 25823  8257]
Scores:  [1.3557736757796552, 2.519825665002863, 3.4085050062563003, 3.9695525038521966, 4.2919329737575325]
Labels:  tensor([0, 2, 3, 0, 2])
Test set: Average loss: 1.4175, Accuracy: 6985/10000 (69.85%)
Dataset indices:  [52012 41383 13682 42198  6185]
Scores:  [1.3061743472090992, 2.3644483581086218, 3.221506615442796, 3.8194846029077567, 4.183660860241003]
Labels:  tensor([8, 0, 8, 4, 3])
Test set: Average loss: 1.2743, Accuracy: 7269/10000 (72.69%)
Dataset indices:  [11657 37137 14866 28222 34614]
Scores:  [1.2659351842478004, 2.3131665302748754, 3.202945514749244, 3.8116075718264586, 4.159970164562334]
Labels:  tensor([0, 5, 7, 6, 2])
Test set: Average loss: 1.1519, Accuracy: 7435/10000 (74.35%)
Dataset indices:  [39411 13642 19396  8488 16077]
Scores:  [1.3163655603620135, 2.405610005940731, 3.1817393501560343, 3.758214079939448, 4.122080265207265]
Labels:  tensor([2, 5, 5, 6, 6])
Test set: Average loss: 0.9635, Accuracy: 7809/10000 (78.09%)
Dataset indices:  [40057  4606 55743 26444 37870]
Scores:  [1.209489071500093, 2.283754189343815, 3.102376195203646, 3.6698826219743843, 4.038958571081122]
Labels:  tensor([5, 9, 3, 1, 8])
Test set: Average loss: 0.7743, Accuracy: 8067/10000 (80.67%)
Dataset indices:  [ 2748 25910 24223 32954 20110]
Scores:  [1.123391331671529, 2.140858614880564, 3.012231409824741, 3.66999233531654, 4.095480093557085]
Labels:  tensor([2, 1, 8, 5, 4])
Test set: Average loss: 0.6680, Accuracy: 8267/10000 (82.67%)
Dataset indices:  [56615 37249 50461   384 32509]
Scores:  [1.2427624719236614, 2.2830006810904986, 3.1605394537163587, 3.7497607635339576, 4.128859502902091]
Labels:  tensor([3, 5, 7, 7, 8])
Test set: Average loss: 0.6514, Accuracy: 8397/10000 (83.97%)
Dataset indices:  [47695 30925 50010  3916 45114]
Scores:  [1.190816694089635, 2.2611525375451773, 3.0947280938353208, 3.7115958775092626, 4.084116729465448]
Labels:  tensor([4, 2, 5, 7, 7])
Test set: Average loss: 0.5701, Accuracy: 8386/10000 (83.86%)
Dataset indices:  [38760 54950  6578 52959 44590]
Scores:  [1.1627632250527844, 2.151829399286887, 2.9537553798530665, 3.559596661670692, 3.9736198748141387]
Labels:  tensor([9, 8, 6, 2, 7])
Test set: Average loss: 0.5139, Accuracy: 8582/10000 (85.82%)
Dataset indices:  [12281 20820 20859 29132 52972]
Scores:  [1.1276134714636667, 2.1698819851983324, 3.0257048656424925, 3.6544162493463603, 4.056693027547438]
Labels:  tensor([2, 9, 8, 8, 3])
Test set: Average loss: 0.5993, Accuracy: 8367/10000 (83.67%)
Dataset indices:  [49202 59080 19590 14699 11295]
Scores:  [1.0977984880766969, 2.0814510505992336, 2.908458520545308, 3.517485210170112, 3.926052066453105]
Labels:  tensor([5, 9, 5, 9, 0])
Test set: Average loss: 0.5477, Accuracy: 8621/10000 (86.21%)
Dataset indices:  [17756 42467 49580 34902 14705]
Scores:  [1.2460383110021542, 2.2770103994311666, 3.181935528898873, 3.7992051764099135, 4.157236509734414]
Labels:  tensor([8, 8, 2, 2, 0])
Test set: Average loss: 0.6217, Accuracy: 8466/10000 (84.66%)
Dataset indices:  [28860 17010  5217 47426 25117]
Scores:  [1.1420065931224535, 2.163338791178303, 3.0353145026285113, 3.689406154914269, 4.095223498725142]
Labels:  tensor([4, 3, 4, 3, 8])
Test set: Average loss: 0.4452, Accuracy: 8754/10000 (87.54%)
Dataset indices:  [59674 40066 29303 30878 43852]
Scores:  [1.0879233508208421, 2.083260109080535, 2.9151471744333244, 3.5294256346467683, 3.9514164379630943]
Labels:  tensor([4, 4, 8, 6, 2])
Test set: Average loss: 0.4564, Accuracy: 8763/10000 (87.63%)
Dataset indices:  [59314 53260 52697 27356  8668]
Scores:  [1.0931448747101902, 2.09011830748354, 2.9307625527521264, 3.570223588524582, 4.0151883704296445]
Labels:  tensor([9, 4, 3, 2, 5])
Test set: Average loss: 0.4157, Accuracy: 8803/10000 (88.03%)
Dataset indices:  [24440 59390 18412 32178  5852]
Scores:  [1.0443426003599554, 2.0138641259236483, 2.86321617007789, 3.505478145903256, 3.9422873447609907]
Labels:  tensor([0, 2, 0, 4, 3])
Test set: Average loss: 0.3696, Accuracy: 8889/10000 (88.89%)
Dataset indices:  [31184 47652  5129 28731 51261]
Scores:  [1.0962478190100569, 2.085744839210468, 2.9357022931217345, 3.5651083882428876, 3.9906569316999683]
Labels:  tensor([9, 2, 2, 2, 4])
Test set: Average loss: 0.3524, Accuracy: 9009/10000 (90.09%)
Dataset indices:  [39151 25387 31637 56391 22675]
Scores:  [1.0255197078227165, 1.9606027634150682, 2.749715548469969, 3.369155913082033, 3.815295016054319]
Labels:  tensor([4, 8, 5, 3, 3])
Test set: Average loss: 0.3498, Accuracy: 8994/10000 (89.94%)
Dataset indices:  [40766 35638  7768 21390 13021]
Scores:  [1.1270052748144128, 2.1798424784191712, 3.040212246578937, 3.635184434645347, 4.036560647852484]
Labels:  tensor([4, 2, 8, 3, 5])
Test set: Average loss: 0.3283, Accuracy: 9124/10000 (91.24%)
Dataset indices:  [44202 26034  2765 36818 29489]
Scores:  [1.0196356716784996, 1.9834245958639172, 2.7933227652841905, 3.41448235566454, 3.85158791628092]
Labels:  tensor([8, 5, 0, 7, 6])
Test set: Average loss: 0.2814, Accuracy: 9234/10000 (92.34%)
Dataset indices:  [37293 18398 33126 43126 30454]
Scores:  [1.1300931680857567, 2.1483018935070217, 2.992901494349929, 3.5947497233707892, 3.9926906528787685]
Labels:  tensor([3, 4, 9, 3, 6])
Test set: Average loss: 0.2732, Accuracy: 9264/10000 (92.64%)
Dataset indices:  [23086 37414  3070  8214  3218]
Scores:  [1.054147318045934, 2.0399407506273706, 2.8545137655874995, 3.479438083830503, 3.9201075658821574]
Labels:  tensor([8, 5, 1, 7, 4])
Test set: Average loss: 0.2742, Accuracy: 9282/10000 (92.82%)
Dataset indices:  [35864 29899 37655 24620  7923]
Scores:  [1.0425523144612032, 1.9722955492461425, 2.769826348292811, 3.409673106042364, 3.855570195163713]
Labels:  tensor([5, 3, 2, 9, 8])
Test set: Average loss: 0.2854, Accuracy: 9261/10000 (92.61%)
Dataset indices:  [43206  5315 38509 40466 28512]
Scores:  [1.0095551073232742, 1.9773855734476835, 2.7935712557665253, 3.4312428375675297, 3.859673478664067]
Labels:  tensor([5, 3, 2, 8, 5])
Test set: Average loss: 0.3089, Accuracy: 9146/10000 (91.46%)
Dataset indices:  [34946 34520 49523 53873 33812]
Scores:  [1.0336427348167723, 1.9970519915069573, 2.797597657927694, 3.42035327890408, 3.8533839231792015]
Labels:  tensor([8, 6, 7, 4, 6])
Test set: Average loss: 0.3097, Accuracy: 9186/10000 (91.86%)
Dataset indices:  [44898  2761 57882 50317 41453]
Scores:  [0.9905177855898044, 1.9297613872862898, 2.7047249345431563, 3.3479105773782156, 3.7841506750832803]
Labels:  tensor([2, 8, 0, 3, 3])
Test set: Average loss: 0.2967, Accuracy: 9241/10000 (92.41%)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># experiment </span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_initial_samples</span><span class="p">,</span> <span class="n">max_training_samples</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">acquisition_batch_size</span><span class="p">),</span> <span class="n">test_accs</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;# training samples&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

