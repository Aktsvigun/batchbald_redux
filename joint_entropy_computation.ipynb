{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp joint_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/blackhc.batchbald/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/blackhc.batchbald\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# joint_entropy\n",
    "> Compute joint entropy estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module to help compute joint entropies for dependent categorical variables given via a density $p((y_i)_i|w))$ in the Bayesian setting. We compute the density $p((y_i)_i)$ by marginalizing over $w$.\n",
    "\n",
    "Two classes are provided:\n",
    "    * exact computation (which works for up 5 to joint variables);\n",
    "    * estimate using MC sampling of configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "import torch\n",
    "from toma import toma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "from toma import toma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run tests, we need a few distributions to run tests with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mixture_prob_dist(p1, p2, m):\n",
    "  return (1. - m) * np.asarray(p1) + m * np.asarray(p2)\n",
    "\n",
    "p1=[0.1,0.2,0.2,0.5]\n",
    "p2=[0.5,0.2,0.1,0.2]\n",
    "get_mixture_prob_dist(p1,p2,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of inference samples `K`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=[0.1,0.2,0.2,0.5]\n",
    "p2=[0.5,0.2,0.1,0.2]\n",
    "y1_ws=[get_mixture_prob_dist(p1,p2,m) for m in np.linspace(0, 1, K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=[0.1,0.6,0.2,0.1]\n",
    "p2=[0.0,0.5,0.5,0.0]\n",
    "y2_ws=[get_mixture_prob_dist(p1,p2,m) for m in np.linspace(0, 1, K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_to_tensor(*l):\n",
    "    return torch.stack(list(map(torch.as_tensor, l))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_ws=nested_to_tensor(y1_ws, y2_ws, y1_ws,y2_ws, y1_ws,y2_ws, y1_ws,y2_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing exact joint entropies\n",
    "\n",
    "To compute exact joint entropies, we have to compute all possible configurations of the $y_i$ and evaluate $p(y_1, \\dots, y_n)$ by averaging over $p(y_1, \\dots, y_n|w)$.\n",
    "\n",
    "The number of samples $M=C^N$, where $N$ is the number of variables in the joint and $C$ is the number of classes.\n",
    "\n",
    "For this, we provide a class `ExactJointEntropy` that takes $K$ and starts with no variables in the joint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "class ExactJointEntropy:\n",
    "    \"\"\"Random variables (all with the same # of categories $C$) can be added via `ExactJointEntropy.add_variables`.\n",
    "\n",
    "`ExactJointEntropy.compute` computes the joint entropy.\n",
    "\n",
    "`ExactJointEntropy.compute_batch` computes the joint entropy of the added variables with each of the variables in the provided batch probabilities in turn.\"\"\"\n",
    "    joint_probs_M_K: torch.Tensor\n",
    "\n",
    "    def __init__(self, joint_probs_M_K: torch.Tensor):\n",
    "        self.joint_probs_M_K = joint_probs_M_K\n",
    "\n",
    "    @staticmethod\n",
    "    def empty(K: int, device=None, dtype=None) -> 'ExactJointEntropy':\n",
    "        return ExactJointEntropy(torch.ones((1, K), device=device,\n",
    "                                            dtype=dtype))\n",
    "\n",
    "    def compute(self) -> torch.Tensor:\n",
    "        probs_M = torch.mean(self.joint_probs_M_K, dim=1, keepdim=False)\n",
    "        nats_M = -torch.log(probs_M) * probs_M\n",
    "        entropy = torch.sum(nats_M)\n",
    "        return entropy\n",
    "\n",
    "    def add_variables(self, probs_N_K_C: torch.Tensor) -> 'ExactJointEntropy':\n",
    "        assert self.joint_probs_M_K.shape[1] == probs_N_K_C.shape[1]\n",
    "\n",
    "        N, K, C = probs_N_K_C.shape\n",
    "        joint_probs_K_M_1 = self.joint_probs_M_K.t()[:, :, None]\n",
    "\n",
    "        # Using lots of memory.\n",
    "        for i in range(N):\n",
    "            probs_i__K_1_C = probs_N_K_C[i][:,\n",
    "                                            None, :].to(joint_probs_K_M_1,\n",
    "                                                        non_blocking=True)\n",
    "            joint_probs_K_M_C = joint_probs_K_M_1 * probs_i__K_1_C\n",
    "            joint_probs_K_M_1 = joint_probs_K_M_C.reshape((K, -1, 1))\n",
    "\n",
    "        joint_probs_M_K = joint_probs_K_M_1.squeeze(2).t()\n",
    "        return ExactJointEntropy(joint_probs_M_K)\n",
    "\n",
    "    def compute_batch(self, probs_B_K_C: torch.Tensor,\n",
    "                            output_entropies_B=None):\n",
    "        assert self.joint_probs_M_K.shape[1] == probs_B_K_C.shape[1]\n",
    "        \n",
    "        B, K, C = probs_B_K_C.shape\n",
    "        M = self.joint_probs_M_K.shape[0]\n",
    "        \n",
    "        if output_entropies_B is None:\n",
    "            output_entropies_B = torch.empty(B, dtype=probs_B_K_C.dtype, device=probs_B_K_C.device)\n",
    "\n",
    "        @toma.execute.chunked(probs_B_K_C,\n",
    "                              initial_step=1024,\n",
    "                              dimension=0,\n",
    "                              context=\"ExactJointEntropy.batch_joint_entropy\")\n",
    "        def chunked_joint_entropy(chunked_probs_b_K_C: torch.Tensor,\n",
    "                                  start: int, end: int):\n",
    "            b = chunked_probs_b_K_C.shape[0]\n",
    "\n",
    "            probs_b_M_C = torch.empty((b, M, C),\n",
    "                                      dtype=self.joint_probs_M_K.dtype,\n",
    "                                      device=self.joint_probs_M_K.device)\n",
    "            for i in range(b):\n",
    "                torch.matmul(self.joint_probs_M_K,\n",
    "                             probs_B_K_C[i].to(self.joint_probs_M_K,\n",
    "                                               non_blocking=True),\n",
    "                             out=probs_b_M_C[i])\n",
    "            probs_b_M_C /= K\n",
    "\n",
    "            output_entropies_B[start:end].copy_(torch.sum(\n",
    "                -torch.log(probs_b_M_C) * probs_b_M_C, dim=(1, 2)),\n",
    "                                                non_blocking=True)\n",
    "            \n",
    "        return output_entropies_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ExactJointEntropy.add_variables\" class=\"doc_header\"><code>ExactJointEntropy.add_variables</code><a href=\"__main__.py#L26\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ExactJointEntropy.add_variables</code>(**`probs_N_K_C`**:`Tensor`)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ExactJointEntropy.compute\" class=\"doc_header\"><code>ExactJointEntropy.compute</code><a href=\"__main__.py#L20\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ExactJointEntropy.compute</code>()\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ExactJointEntropy.compute_batch\" class=\"doc_header\"><code>ExactJointEntropy.compute_batch</code><a href=\"__main__.py#L43\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ExactJointEntropy.compute_batch</code>(**`probs_B_K_C`**:`Tensor`, **`output_entropies_B`**=*`None`*)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ExactJointEntropy.add_variables)\n",
    "show_doc(ExactJointEntropy.compute)\n",
    "show_doc(ExactJointEntropy.compute_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6479, dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_joint_entropy = ExactJointEntropy.empty(K, dtype=torch.double)\n",
    "entropy = exact_joint_entropy.add_variables(ys_ws[:4]).compute()\n",
    "assert np.isclose(entropy, 4.6479, atol=0.1)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6479)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_joint_entropy = ExactJointEntropy.empty(K, dtype=torch.float)\n",
    "entropy = exact_joint_entropy.add_variables(ys_ws[:4]).compute()\n",
    "assert np.isclose(entropy, 4.6479, atol=0.1)\n",
    "entropy\n",
    "exact_joint_entropy.expand_joint(ys_ws[:4]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.9735, 5.6362, 5.9735, 5.6362, 5.9735, 5.6362, 5.9735, 5.6362],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_joint_entropy = ExactJointEntropy.empty(K, dtype=torch.float)\n",
    "entropies =exact_joint_entropy.add_variables(ys_ws[:4]).compute_batch(ys_ws)\n",
    "assert np.allclose(entropies, [5.9735, 5.6362, 5.9735, 5.6362, 5.9735, 5.6362, 5.9735, 5.6362])\n",
    "entropies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing  approximate joint entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
