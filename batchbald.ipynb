{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp batchbald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T13:03:48.502329Z",
     "start_time": "2020-04-24T13:03:48.385548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/batchbald_redux/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/batchbald_redux\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchBALD Algorithm\n",
    "> Greedy algorithm and score computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will implement two helper classes to compute conditional entropies $H[y_i|w]$ and entropies $H[y_i]$.\n",
    "\n",
    "Then, we will implement BatchBALD and BALD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T15:09:13.677310Z",
     "start_time": "2020-04-24T15:09:13.579673Z"
    }
   },
   "outputs": [],
   "source": [
    "# exports\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import torch\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from toma import toma\n",
    "\n",
    "from batchbald_redux import joint_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to define a couple of sampled distributions to use for our testing our code.\n",
    "\n",
    "We are going to use $K=20$ inference samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T13:03:49.889852Z",
     "start_time": "2020-04-24T13:03:49.880634Z"
    }
   },
   "outputs": [],
   "source": [
    "K=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T13:08:00.570589Z",
     "start_time": "2020-04-24T13:08:00.555804Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_mixture_prob_dist(p1, p2, m):\n",
    "    return (1. - m) * np.asarray(p1) + m * np.asarray(p2)\n",
    "\n",
    "\n",
    "p1 = [0.7, 0.1, 0.1, 0.1]\n",
    "p2 = [0.3, 0.3, 0.2, 0.2]\n",
    "y1_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.7, 0.1, 0.1]\n",
    "p2 = [0.2, 0.3, 0.3, 0.2]\n",
    "y2_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.7, 0.1]\n",
    "p2 = [0.2, 0.2, 0.3, 0.3]\n",
    "y3_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.1, 0.7]\n",
    "p2 = [0.3, 0.2, 0.2, 0.3]\n",
    "y4_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "\n",
    "def nested_to_tensor(l):\n",
    "    return torch.stack(list(map(torch.as_tensor, l)))\n",
    "\n",
    "\n",
    "ys_ws = nested_to_tensor([y1_ws, y2_ws, y3_ws, y4_ws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T13:08:00.570589Z",
     "start_time": "2020-04-24T13:08:00.555804Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "p = [0.25, 0.25, 0.25, 0.25]\n",
    "yu_ws = [p for m in range(K)]\n",
    "yus_ws = nested_to_tensor([yu_ws]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T13:08:01.985251Z",
     "start_time": "2020-04-24T13:08:01.977149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 20, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing conditional entropies and batch entropies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T15:13:33.643664Z",
     "start_time": "2020-04-24T15:13:33.571926Z"
    }
   },
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "DBL_NULL_THRESHOLD = 1e-200\n",
    "\n",
    "def compute_conditional_entropy(probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = probs_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    pbar = tqdm(total=N, desc=\"Conditional Entropy\", leave=False)\n",
    "\n",
    "    @toma.execute.chunked(probs_N_K_C, 1024)\n",
    "    def compute(probs_n_K_C, start: int, end: int):\n",
    "        nats_n_K_C = probs_n_K_C * torch.log(probs_n_K_C)\n",
    "        \n",
    "        entropies_N[start:end].copy_(\n",
    "            -torch.sum(nats_n_K_C, dim=(1, 2)) / K)\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    return entropies_N\n",
    "\n",
    "\n",
    "def compute_conditional_entropy_from_logits(logits_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = logits_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    pbar = tqdm(total=N, desc=\"Conditional Entropy\", leave=False)\n",
    "\n",
    "    @toma.execute.chunked(logits_N_K_C, 1024)\n",
    "    def compute(logits_n_K_C, start: int, end: int):\n",
    "        nats_n_K_C = logits_n_K_C * torch.exp(logits_n_K_C)\n",
    "        \n",
    "        entropies_N[start:end].copy_(\n",
    "            -torch.sum(nats_n_K_C, dim=(1, 2)) / K)\n",
    "        pbar.update(end - start)\n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    return entropies_N\n",
    "\n",
    "\n",
    "def compute_entropy(probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = probs_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    pbar = tqdm(total=N, desc=\"Entropy\", leave=False)\n",
    "\n",
    "    @toma.execute.chunked(probs_N_K_C, 1024)\n",
    "    def compute(probs_n_K_C, start: int, end: int):\n",
    "        mean_probs_n_C = probs_n_K_C.mean(dim=1)\n",
    "        nats_n_C = mean_probs_n_C * torch.log(mean_probs_n_C)\n",
    "        nats_n_C[mean_probs_n_C < DBL_NULL_THRESHOLD] = 0.\n",
    "        \n",
    "        entropies_N[start:end].copy_(\n",
    "            -torch.sum(nats_n_C, dim=1))\n",
    "        pbar.update(end - start)\n",
    "        \n",
    "    pbar.close()\n",
    "\n",
    "    return entropies_N\n",
    "\n",
    "\n",
    "def compute_entropy_from_logits(logits_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = logits_N_K_C.shape\n",
    "\n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "\n",
    "    pbar = tqdm(total=N, desc=\"Entropy\", leave=False)\n",
    "\n",
    "    @toma.execute.chunked(logits_N_K_C, 1024)\n",
    "    def compute(logits_n_K_C, start: int, end: int):\n",
    "        mean_logits_n_C = torch.logsumexp(logits_n_K_C, dim=1) - math.log(K)\n",
    "        nats_n_C = mean_logits_n_C * torch.exp(mean_logits_n_C)\n",
    "        \n",
    "        entropies_N[start:end].copy_(\n",
    "            -torch.sum(nats_n_C, dim=1))\n",
    "        pbar.update(end - start)\n",
    "        \n",
    "    pbar.close()\n",
    "\n",
    "    return entropies_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T15:13:36.476342Z",
     "start_time": "2020-04-24T15:13:35.862292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Conditional Entropy', max=4, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Conditional Entropy', max=4, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Entropy', max=4, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Entropy', max=4, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make sure everything is computed correctly.\n",
    "\n",
    "assert np.allclose(compute_conditional_entropy(yus_ws), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)\n",
    "assert np.allclose(compute_conditional_entropy_from_logits(yus_ws.log()), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)\n",
    "assert np.allclose(compute_entropy(yus_ws), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)\n",
    "assert np.allclose(compute_entropy_from_logits(yus_ws.log()), [1.3863, 1.3863, 1.3863, 1.3863], atol=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T15:13:37.674573Z",
     "start_time": "2020-04-24T15:13:37.503258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Conditional Entropy', max=4, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2069, 1.2069, 1.2069, 1.2069], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "conditional_entropies = compute_conditional_entropy(ys_ws)\n",
    "\n",
    "print(conditional_entropies)\n",
    "\n",
    "assert np.allclose(conditional_entropies, [1.2069, 1.2069, 1.2069, 1.2069],\n",
    "                   atol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T14:13:57.530178Z",
     "start_time": "2020-04-24T14:13:57.403597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Entropy', max=4, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "tensor([1.2376, 1.2376, 1.2376, 1.2376], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "entropies = compute_entropy(ys_ws)\n",
    "\n",
    "print(entropies)\n",
    "\n",
    "assert np.allclose(entropies,\n",
    "    [1.2376, 1.2376, 1.2376, 1.2376],\n",
    "                   atol=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchBALD\n",
    "\n",
    "To compute BatchBALD exactly for a candidate batch, we'd have to compute $I[(y_b)_B;w] = H[(y_b)_B] - H[(y_b)_B|w]$.\n",
    "\n",
    "As the $y_b$ are independent given $w$, we can simplify $H[(y_b)_B|w] = \\sum_b H[y_b|w]$.\n",
    "\n",
    "Furthermore, we use a greedy algorithm to build up the candidate batch, so $y_1,\\dots,y_{B-1}$ will stay fixed as we determine $y_{B}$. We compute\n",
    "$H[(y_b)_{B-1}, y_i] - H[y_i|w]$ for each pool element $y_i$ and add the highest scorer as $y_{B}$.\n",
    "\n",
    "We don't utilize the last optimization here in order to compute the actual scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the paper\n",
    "\n",
    "![BatchBALD algorithm in the paper](batchbald_algorithm.png)\n",
    "\n",
    "\n",
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T15:11:07.099502Z",
     "start_time": "2020-04-24T15:11:07.084153Z"
    }
   },
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CandidateBatch:\n",
    "    scores: List[float]\n",
    "    indices: List[int]\n",
    "\n",
    "\n",
    "def get_batchbald_batch(logits_N_K_C: torch.Tensor,\n",
    "                        batch_size: int,\n",
    "                        num_samples: int,\n",
    "                        dtype=None,\n",
    "                        device=None) -> CandidateBatch:\n",
    "    N, K, C = logits_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "    \n",
    "    conditional_entropies_N = compute_conditional_entropy_from_logits(logits_N_K_C)\n",
    "       \n",
    "    probs_N_K_C = logits_N_K_C.exp()\n",
    "    logits_N_K_C = None\n",
    "\n",
    "    batch_joint_entropy = joint_entropy.DynamicJointEntropy(num_samples,\n",
    "                                                            batch_size - 1,\n",
    "                                                            K,\n",
    "                                                            C,\n",
    "                                                            dtype=dtype,\n",
    "                                                            device=device)\n",
    "\n",
    "\n",
    "    # We always keep these on the CPU.\n",
    "    scores_N = torch.empty(N, dtype=torch.double, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    for i in tqdm(range(batch_size), desc=\"BatchBALD\", leave=False):\n",
    "        if i > 0:\n",
    "            latest_index = candidate_indices[-1]\n",
    "            batch_joint_entropy.add_variables(\n",
    "                probs_N_K_C[latest_index:latest_index + 1])\n",
    "\n",
    "        shared_conditinal_entropies = conditional_entropies_N[\n",
    "            candidate_indices].sum()\n",
    "\n",
    "        batch_joint_entropy.compute_batch(probs_N_K_C,\n",
    "                                          output_entropies_B=scores_N)\n",
    "\n",
    "        scores_N -= conditional_entropies_N + shared_conditinal_entropies\n",
    "        scores_N[candidate_indices] = -float('inf')\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T15:11:08.643748Z",
     "start_time": "2020-04-24T15:11:07.874911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Conditional Entropy', max=4, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2069, 1.2069, 1.2069, 1.2069], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='BatchBALD', max=4, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ExactJointEntropy.compute_batch', max=4, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0307, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ExactJointEntropy.compute_batch', max=4, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0596, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ExactJointEntropy.compute_batch', max=4, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0869, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='ExactJointEntropy.compute_batch', max=4, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1128, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.05961958627158248, 0.0869107051474467, 0.11275304532467878], indices=[3, 2, 1, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batchbald_batch(ys_ws.double().log(), 4, 1000, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BALD\n",
    "\n",
    "BALD is the same as BatchBALD, except that we evaluate points individually, by computing $I[y_i;w]$ for each, and then take the top $B$ scorers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T15:11:01.334394Z",
     "start_time": "2020-04-24T15:11:01.322109Z"
    }
   },
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_bald_batch(logits_N_K_C: torch.Tensor,\n",
    "                   batch_size: int,\n",
    "                   dtype=None,\n",
    "                   device=None) -> CandidateBatch:\n",
    "    N, K, C = logits_N_K_C.shape\n",
    "\n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    scores_N = -compute_conditional_entropy_from_logits(logits_N_K_C)\n",
    "    scores_N += compute_entropy_from_logits(logits_N_K_C)\n",
    "\n",
    "    candiate_scores, candidate_indices = torch.topk(scores_N, batch_size)\n",
    "\n",
    "    return CandidateBatch(candiate_scores.tolist(), candidate_indices.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-24T15:11:32.752143Z",
     "start_time": "2020-04-24T15:11:32.430590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Conditional Entropy', max=4, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2069, -1.2069, -1.2069, -1.2069], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Entropy', max=4, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.030715639666234917, 0.030715639666234917, 0.030715639666234917], indices=[2, 3, 0, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bald_batch(ys_ws.double().log(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
