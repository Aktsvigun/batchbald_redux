{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp batchbald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchBALD Algorithm\n",
    "> Greedy algorithm and score computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will implement two helper classes to compute conditional entropies $H[y_i|w]$ and entropies $H[y_i]$.\n",
    "\n",
    "Then, we will implement BatchBALD and BALD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import torch\n",
    "\n",
    "from toma import toma\n",
    "\n",
    "from batchbald_redux import joint_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to define a couple of sampled distributions to use for our testing our code.\n",
    "\n",
    "We are going to use $K=20$ inference samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_mixture_prob_dist(p1, p2, m):\n",
    "    return (1. - m) * np.asarray(p1) + m * np.asarray(p2)\n",
    "\n",
    "\n",
    "# p1 = [0.1, 0.2, 0.2, 0.5]\n",
    "# p2 = [0.5, 0.2, 0.1, 0.2]\n",
    "# y1_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "# p1 = [0.1, 0.6, 0.2, 0.1]\n",
    "# p2 = [0.1, 0.4, 0.4, 0.1]\n",
    "# y2_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "# p1 = [0.1, 0.1, 0.6, 0.2]\n",
    "# p2 = [0.1, 0.1, 0.5, 0.3]\n",
    "# y3_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "# p1 = [0.1, 0.1, 0.1, 0.7]\n",
    "# p2 = [0.1, 0.5, 0.1, 0.3]\n",
    "# y4_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.7, 0.1, 0.1, 0.1]\n",
    "p2 = [0.3, 0.3, 0.2, 0.2]\n",
    "y1_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.7, 0.1, 0.1]\n",
    "p2 = [0.2, 0.3, 0.3, 0.2]\n",
    "y2_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.7, 0.1]\n",
    "p2 = [0.2, 0.2, 0.3, 0.3]\n",
    "y3_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "p1 = [0.1, 0.1, 0.1, 0.7]\n",
    "p2 = [0.3, 0.2, 0.2, 0.3]\n",
    "y4_ws = [get_mixture_prob_dist(p1, p2, m) for m in np.linspace(0, 1, K)]\n",
    "\n",
    "\n",
    "def nested_to_tensor(l):\n",
    "    return torch.stack(list(map(torch.as_tensor, l)))\n",
    "\n",
    "\n",
    "duplicates=2 \n",
    "\n",
    "ys_ws = nested_to_tensor([y1_ws] * duplicates + [y2_ws] * duplicates + [y3_ws] * duplicates + [y4_ws] * duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 20, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys_ws.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing conditional entropies and batch entropies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "def compute_conditional_entropy(probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = probs_N_K_C.shape\n",
    "    \n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "    @toma.execute.chunked(probs_N_K_C, 1024)\n",
    "    def compute(probs_n_K_C, start:int, end: int):\n",
    "        entropies_N[start:end].copy_(-torch.sum(probs_n_K_C*torch.log(probs_n_K_C), dim=(1,2))/K)\n",
    "    \n",
    "    return entropies_N\n",
    "\n",
    "\n",
    "def compute_entropy(probs_N_K_C: torch.Tensor) -> torch.Tensor:\n",
    "    N, K, C = probs_N_K_C.shape\n",
    "    \n",
    "    entropies_N = torch.empty(N, dtype=torch.double)\n",
    "    @toma.execute.chunked(probs_N_K_C, 1024)\n",
    "    def compute(probs_n_K_C, start:int, end: int):\n",
    "        mean_probs_N_C = probs_N_K_C.mean(dim=1)        \n",
    "        entropies_N[start:end].copy_(-torch.sum(mean_probs_N_C*torch.log(mean_probs_N_C), dim=1))\n",
    "    \n",
    "    return entropies_N\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "conditional_entropies = compute_conditional_entropy(ys_ws)\n",
    "\n",
    "print(conditional_entropies)\n",
    "\n",
    "assert np.allclose(conditional_entropies, [1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069, 1.2069],\n",
    "                   atol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2376, 1.2376, 1.2376, 1.2376, 1.2376, 1.2376, 1.2376, 1.2376],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "entropies = compute_entropy(ys_ws)\n",
    "\n",
    "print(entropies)\n",
    "\n",
    "assert np.allclose(entropies,\n",
    "    [1.2376, 1.2376, 1.2376, 1.2376, 1.2376, 1.2376, 1.2376, 1.2376],\n",
    "                   atol=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchBALD\n",
    "\n",
    "To compute BatchBALD exactly for a candidate batch, we'd have to compute $I[(y_b)_B;w] = H[(y_b)_B] - H[(y_b)_B|w]$.\n",
    "\n",
    "As the $y_b$ are independent given $w$, we can simplify $H[(y_b)_B|w] = \\sum_b H[y_b|w]$.\n",
    "\n",
    "Furthermore, we use a greedy algorithm to build up the candidate batch, so $y_1,\\dots,y_{B-1}$ will stay fixed as we determine $y_{B}$. We compute\n",
    "$H[(y_b)_{B-1}, y_i] - H[y_i|w]$ for each pool element $y_i$ and add the highest scorer as $y_{B}$.\n",
    "\n",
    "We don't utilize the last optimization here in order to compute the actual scores.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the paper\n",
    "\n",
    "![BatchBALD algorithm in the paper](batchbald_algorithm.png)\n",
    "\n",
    "\n",
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CandidateBatch:\n",
    "    scores: List[float]\n",
    "    indices: List[int]\n",
    "\n",
    "\n",
    "def get_batchbald_batch(probs_N_K_C: torch.Tensor,\n",
    "                        batch_size: int,\n",
    "                        num_samples: int,\n",
    "                        dtype=None,\n",
    "                        device=None) -> CandidateBatch:\n",
    "    N, K, C = probs_N_K_C.shape\n",
    "    \n",
    "    batch_size = min(batch_size, N)\n",
    "    \n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "    \n",
    "    if batch_size == 0:\n",
    "        return CandidateBatch(candidate_scores, candidate_indices)\n",
    "\n",
    "    batch_joint_entropy = joint_entropy.DynamicJointEntropy(num_samples,\n",
    "                                                            batch_size - 1,\n",
    "                                                            K,\n",
    "                                                            C,\n",
    "                                                            dtype=dtype,\n",
    "                                                            device=device)\n",
    "\n",
    "    conditional_entropies_N = compute_conditional_entropy(probs_N_K_C)\n",
    "\n",
    "    # We always keep these on the CPU.\n",
    "    scores_N = torch.empty(N, dtype=torch.double)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        if i > 0:\n",
    "            latest_index = candidate_indices[-1]\n",
    "            batch_joint_entropy.add_variables(\n",
    "                probs_N_K_C[latest_index:latest_index + 1])\n",
    "        \n",
    "        shared_conditinal_entropies = conditional_entropies_N[candidate_indices].sum()\n",
    "        \n",
    "        batch_joint_entropy.compute_batch(probs_N_K_C,\n",
    "                                          output_entropies_B=scores_N)\n",
    "        \n",
    "        scores_N -= conditional_entropies_N + shared_conditinal_entropies\n",
    "        scores_N[candidate_indices] = -float('inf')\n",
    "        \n",
    "        print(scores_N)\n",
    "\n",
    "        candidate_score, candidate_index = scores_N.max(dim=0)\n",
    "\n",
    "        candidate_indices.append(candidate_index.item())\n",
    "        candidate_scores.append(candidate_score.item())\n",
    "\n",
    "    return CandidateBatch(candidate_scores, candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0307, 0.0307, 0.0307, 0.0307, 0.0307, 0.0307, 0.0307, 0.0307],\n",
      "       dtype=torch.float64)\n",
      "tensor([0.0596, 0.0596, 0.0596, 0.0596, 0.0596, 0.0596, 0.0596,   -inf],\n",
      "       dtype=torch.float64)\n",
      "tensor([0.0869, 0.0869, 0.0869, 0.0869, 0.0869, 0.0869,   -inf,   -inf],\n",
      "       dtype=torch.float64)\n",
      "tensor([0.1128, 0.1128, 0.1128, 0.1128, 0.1128,   -inf,   -inf,   -inf],\n",
      "       dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.059619586271582925, 0.08691070514744759, 0.11275304532467789], indices=[7, 6, 5, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batchbald_batch(ys_ws.double(), 4, 1000, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encore: BALD\n",
    "\n",
    "BALD is the same as BatchBALD, except that we pick candidates independently from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bald_batch(probs_N_K_C: torch.Tensor,\n",
    "                   batch_size: int,\n",
    "                   num_samples: int,\n",
    "                   dtype=None,\n",
    "                   device=None) -> CandidateBatch:\n",
    "    N, K, C = probs_N_K_C.shape\n",
    "    \n",
    "    batch_size = min(batch_size, N)\n",
    "\n",
    "    candidate_indices = []\n",
    "    candidate_scores = []\n",
    "\n",
    "    scores_N = compute_entropy(probs_N_K_C)\n",
    "    scores_N -= compute_conditional_entropy(probs_N_K_C)\n",
    "    \n",
    "    candiate_scores, candidate_indices = torch.topk(scores_N, batch_size)\n",
    "    \n",
    "    return CandidateBatch(candiate_scores.tolist(), candidate_indices.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CandidateBatch(scores=[0.030715639666234917, 0.030715639666234917, 0.030715639666234917, 0.030715639666234917], indices=[2, 6, 3, 7])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bald_batch(ys_ws.double(), 4, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
